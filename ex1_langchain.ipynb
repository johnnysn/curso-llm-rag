{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Uma pipeline simples para retornar piadas em PT-BR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'tema': {'title': 'Tema', 'type': 'string'}},\n",
       " 'required': ['tema'],\n",
       " 'title': 'PromptInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'Você é um humorista e faz piadas conforme solicitado pelo usuário.'),\n",
    "    ('human', 'Faça uma piada sobre o tema: {tema}')\n",
    "])\n",
    "model = Ollama(model='llama3.1')\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Por aqui!\\n\\nVocê sabe por que a cadeira foi para o psicólogo? Porque estava sentindo-se \"deslocada\" e tinha problemas de \"estar assentando as coisas\"... E agora está \"sentindo-se\" muito melhor! (risos)'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'tema': 'cadeira'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Então, você sabe por que eu sempre sento na cadeira? É porque ela sempre tem um bom lugar para se sentar... E é só uma brincadeira! Mas sério, a minha casa está cheia de cadeiras em espera. Elas estão sempre dizendo: \"Quando vou ser sentada?\"\n"
     ]
    }
   ],
   "source": [
    "stream = chain.stream({'tema': 'cadeira'})\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Pipeline simples para fazer piadas em inglês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'PromptInput', 'type': 'object'}\n",
      "Here's one:\n",
      "\n",
      "\"You know what they say, 'A good chair can be a real seat-saver.' But let's be honest, most chairs are just a bunch of legs... I mean, literally. They've got legs, an arse, and a back... that's basically just a fancy way of saying they're like your aunt after a few too many drinks!\"\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate([\n",
    "    ('system', 'You are a comedian and make jokes as requested by the user.'),\n",
    "    ('human', 'Tell me a joke about the topic: {topic}')\n",
    "])\n",
    "\n",
    "model = Ollama(model='llama3.1')\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "print(chain.input_schema.schema())\n",
    "\n",
    "# topic = input('Enter a topic for the question: ')\n",
    "\n",
    "stream = chain.stream({'topic': 'chair'})\n",
    "for chunk in stream:\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Criando pipeline de tradução para PT-BR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sê amável com as pessoas o tempo todo, Jeremy.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_translate = PromptTemplate.from_template(\"Translate the following piece of text into portuguese (BR). Provide the translation ONLY. \\n {text}\")\n",
    "\n",
    "# model_translate = Ollama(model=\"llama3.1\", temperature = 0.1)\n",
    "\n",
    "chain_translate = prompt_translate | model | StrOutputParser()\n",
    "\n",
    "print(chain_translate.invoke({'text': 'Be nice to people all the time, Jeremy'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'StrOutputParserOutput', 'type': 'string'}\n",
      "{'properties': {'text': {'title': 'Text', 'type': 'string'}}, 'required': ['text'], 'title': 'PromptInput', 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "print(chain.output_schema.schema())\n",
    "\n",
    "print(chain_translate.input_schema.schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Compondo pipelines de tradução com a de piadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Por que o computador foi para terapia? Porque ele tinha um vírus... e não só no seu disco rígido, mas também em seu programa de código. Sim, é um problema realmente de bytes!\" (bum-tss)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "composed_chain = chain | {'text': RunnablePassthrough()} | chain_translate\n",
    "\n",
    "print(composed_chain.invoke({'topic': 'computer'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aqui vamos!\n",
      "\n",
      "Por que o brasileiro levou uma escada para a festa?\n",
      "\n",
      "Porque ouviu dizer que as bebidas estavam de graça! (entendeu?)\n"
     ]
    }
   ],
   "source": [
    "prompt_input = PromptTemplate.from_template(\"Translate the following portuguese topic into english. Provide ONLY the translation. \\n {tema}\")\n",
    "\n",
    "composed_chain = (\n",
    "    prompt_input \n",
    "    | model \n",
    "    | StrOutputParser()\n",
    "    | {'topic': RunnablePassthrough()}\n",
    "    | chain\n",
    "    | {'text': RunnablePassthrough()}\n",
    "    | chain_translate\n",
    ")\n",
    "\n",
    "stream = composed_chain.stream({'tema', 'brasileiros'})\n",
    "for chunk in stream:\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
